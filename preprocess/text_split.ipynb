{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split filelist file into train and test sets\n",
    "\n",
    "Use a train ratio or number of samples in test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/daniilrobnikov/Developer/TTS/vits-bengali\n",
      "LICENSE                         \u001b[34mpreprocess\u001b[m\u001b[m/\n",
      "README.md                       preprocess.py\n",
      "attentions.py                   requirements.txt\n",
      "batch_inference.ipynb           \u001b[34mresources\u001b[m\u001b[m/\n",
      "commons.py                      test-env.md\n",
      "\u001b[34mconfigs\u001b[m\u001b[m/                        test-gpu_monotonic_align.ipynb\n",
      "data_utils.py                   test-madasr23-links.txt\n",
      "\u001b[34mfilelists\u001b[m\u001b[m/                      test-todo.txt\n",
      "inference.ipynb                 test_torchaudio.ipynb\n",
      "losses.py                       \u001b[34mtext\u001b[m\u001b[m/\n",
      "mel_processing.py               train.py\n",
      "models.py                       train_ms.py\n",
      "modules.py                      transforms.py\n",
      "monotonic_align.py              utils.py\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the csv file\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "dataset_name = \"madasr23\"\n",
    "data = pd.read_csv(f\"filelists/{dataset_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support for DataFrames\n",
    "def split_file_list(orig_data, train_ratio=None, test_samples=None, max_samples=None):\n",
    "    # Shuffle the data\n",
    "    data = orig_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    if max_samples is not None:\n",
    "        data = data[:max_samples]\n",
    "\n",
    "    if test_samples is not None:\n",
    "        train_set = data[:-test_samples]\n",
    "        test_set = data[-test_samples:]\n",
    "    elif train_ratio is not None:\n",
    "        train_set_size = int(len(data) * train_ratio)\n",
    "        train_set = data[:train_set_size]\n",
    "        test_set = data[train_set_size:]\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Either 'train_ratio' or 'test_samples' should be provided.\")\n",
    "\n",
    "    return train_set, test_set\n",
    "\n",
    "\n",
    "# Example usage\n",
    "train_data, val_data = split_file_list(data, test_samples=1240)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map speaker ids to speaker indexes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map speaker IDs to their indices\n",
    "sids = data[\"spkid\"].unique()\n",
    "sid2idx = {sid: index for index, sid in enumerate(sids)}\n",
    "idx2sid = {index: sid for index, sid in enumerate(sids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save speaker id to speaker index mapping to .csv file\n",
    "sid2idx_df = pd.DataFrame.from_dict(sid2idx, orient=\"index\")\n",
    "sid2idx_df.to_csv(f\"filelists/{dataset_name}_sid2idx.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save phonemes and text of train_data, val_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closest path to wav directory\n",
    "# F.e. /Users/usr/datasets/madasr23/bn\n",
    "source_dir = \"/gpfs/mariana/home/darobn/datasets/madasr23/bn\"\n",
    "train_file_path = f\"filelists/{dataset_name}_audio_sid_text_train_filelist.txt\"\n",
    "val_file_path = f\"filelists/{dataset_name}_audio_sid_text_val_filelist.txt\"\n",
    "link_name = \"DUMMY3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_path_map(source_dir):\n",
    "    path_map = {}\n",
    "    for root, dirs, files in os.walk(source_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".wav\"):\n",
    "                path_map[file] = os.path.join(root, file)\n",
    "    return path_map\n",
    "\n",
    "\n",
    "def save_file_list(data, out_file_path, source_dir, path_map, link_name, cleaned_text=False):\n",
    "    out_file_path = out_file_path if not cleaned_text else out_file_path.replace(\n",
    "        \".txt\", \".txt.cleaned\")\n",
    "    with open(out_file_path, \"w\") as file:\n",
    "        for row in data.itertuples():\n",
    "            uttid = f\"{row.uttid}.wav\"\n",
    "            path = path_map[uttid].replace(source_dir, link_name)\n",
    "            sid = sid2idx[row.spkid]\n",
    "            info = row.text if not cleaned_text else row.phonemes\n",
    "\n",
    "            file.write(f\"{path}|{sid}|{info}\\n\")\n",
    "            # Print every nth sample\n",
    "            if row.Index % 2000 == 0:\n",
    "                print(f\"{row.Index}: {path}|{sid}|{info}\")\n",
    "\n",
    "    print(f\"Saved to '{out_file_path}' ({len(data)} samples).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to 'filelists/madasr23dataset_audio_sid_text_train_filelist.txt' (579996 samples).\n",
      "Saved to 'filelists/madasr23dataset_audio_sid_text_dev_filelist.txt' (1240 samples).\n",
      "Saved to 'filelists/madasr23dataset_audio_sid_text_train_filelist.txt.cleaned' (579996 samples).\n",
      "Saved to 'filelists/madasr23dataset_audio_sid_text_dev_filelist.txt.cleaned' (1240 samples).\n"
     ]
    }
   ],
   "source": [
    "path_map = create_path_map(source_dir)\n",
    "\n",
    "\n",
    "save_file_list(train_data, train_file_path, source_dir, path_map, link_name)\n",
    "save_file_list(val_data, val_file_path, source_dir, path_map, link_name)\n",
    "save_file_list(train_data, train_file_path, source_dir, path_map, link_name, cleaned_text=True)\n",
    "save_file_list(val_data, val_file_path, source_dir, path_map, link_name, cleaned_text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a symlink to the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create symlink to the dataset\n",
    "!ln -s {source_dir} {link_name}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
