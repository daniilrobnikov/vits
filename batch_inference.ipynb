{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchaudio\n",
    "\n",
    "import commons\n",
    "import utils\n",
    "from models import SynthesizerTrn\n",
    "from text.symbols import symbols\n",
    "from text import text_to_sequence\n",
    "\n",
    "\n",
    "def get_text(text, hps):\n",
    "    text_norm = text_to_sequence(text, hps.data.text_cleaners)\n",
    "    if hps.data.add_blank:\n",
    "        text_norm = commons.intersperse(text_norm, 0)\n",
    "    text_norm = torch.LongTensor(text_norm)\n",
    "    return text_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data as\n",
    "import pandas as pd\n",
    "\n",
    "i_file = \"filelists/custom_test.csv\"\n",
    "o_dir = \"path/to/output/dir\"\n",
    "data = pd.read_csv(i_file, sep=\"|\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MADASR23 batch inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps = utils.get_hparams_from_file(\"./configs/custom_base.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_g = SynthesizerTrn(len(symbols), hps.data.filter_length // 2 + 1, hps.train.segment_size // hps.data.hop_length, n_speakers=hps.data.n_speakers, **hps.model).cuda()\n",
    "_ = net_g.eval()\n",
    "\n",
    "_ = utils.load_checkpoint(\"./logs/custom_base/G_15000.pth\", net_g, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, dataframe, hps):\n",
    "        self.data = dataframe\n",
    "        self.hps = hps\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sid_idx = self.data[\"sid_idx\"][idx]\n",
    "        sid = self.data[\"sid\"][idx]\n",
    "        phonemes = self.data[\"phonemes\"][idx]\n",
    "        stn_tst = get_text(phonemes, self.hps)\n",
    "        return sid_idx, sid, stn_tst, idx\n",
    "\n",
    "\n",
    "# Initialize the dataset and data loader\n",
    "dataset = MyDataset(data, hps)\n",
    "data_loader = DataLoader(dataset, batch_size=1, num_workers=8)\n",
    "\n",
    "for sid_idx, spk_id, stn_tst, i in tqdm(data_loader):\n",
    "    sid_idx = int(sid_idx)\n",
    "    spk_id = int(spk_id)\n",
    "    i = int(i)\n",
    "    stn_tst = stn_tst[0]\n",
    "    with torch.no_grad():\n",
    "        x_tst = stn_tst.cuda().unsqueeze(0)\n",
    "        x_tst_lengths = torch.LongTensor([stn_tst.size(0)]).cuda()\n",
    "        sid = torch.LongTensor([sid_idx]).cuda()\n",
    "        audio = net_g.infer(x_tst, x_tst_lengths, sid=sid, noise_scale=0.667, noise_scale_w=0.8, length_scale=1)[0][0].data.cpu()\n",
    "        torchaudio.save(f\"{o_dir}/{spk_id}_{i}.wav\", audio, hps.data.sampling_rate, bits_per_sample=hps.data.bits_per_sample)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voice Conversion\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
